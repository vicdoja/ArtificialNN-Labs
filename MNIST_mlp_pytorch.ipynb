{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Constants definition\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "num_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataloaders\n",
    "data_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(28, padding=4),\n",
    "    torchvision.transforms.RandomAffine(degrees=5, translate=(0.10, 0.15), scale=(0.9, 1.1)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST('.data/', train=True, download=True, transform=data_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST('.data/', train=False, download=True, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 60000 samples - Max value: 1.0 - Min value: -1.0\n",
      "Test set: 10000 samples - Max value: 1.0 - Min value: -1.0\n",
      "Example batch shape: torch.Size([256, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Statistics printing\n",
    "x_batch, y_batch = iter(train_loader).next()\n",
    "print(\"Training set: {} samples - Max value: {} - Min value: {}\".format(len(train_loader.dataset),\n",
    "                                                                        x_batch.max(), x_batch.min()))\n",
    "x_batch, y_batch = iter(test_loader).next()\n",
    "print(\"Test set: {} samples - Max value: {} - Min value: {}\".format(len(test_loader.dataset),\n",
    "                                                                    x_batch.max(), x_batch.min()))\n",
    "print(\"Example batch shape: {}\".format(x_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no GaussianNoise Layer in Pytorch\n",
    "# https://discuss.pytorch.org/t/writing-a-simple-gaussian-noise-layer-in-pytorch/4694/4\n",
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.noise = torch.tensor(0).to(device).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x\n",
    "\n",
    "# Creating our Neural Network - Fully Connected\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.gn0 = GaussianNoise(0.1)\n",
    "        \n",
    "        self.linear1 = nn.Linear(784, 1024)\n",
    "        self.norm1 = nn.BatchNorm1d(1024)\n",
    "        self.gn1 = GaussianNoise(0.1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(1024, 1024)\n",
    "        self.norm2 = nn.BatchNorm1d(1024)\n",
    "        self.gn2 = GaussianNoise(0.1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        '''self.linear3 = nn.Linear(1024, 1024)\n",
    "        self.norm3 = nn.BatchNorm1d(1024)\n",
    "        self.gn3 = GaussianNoise(0.1)\n",
    "        self.relu3 = nn.ReLU()'''\n",
    "        \n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.gn0(x)\n",
    "        out = self.relu1(self.gn1(self.norm1(self.linear1(out))))\n",
    "        out = self.relu2(self.gn2(self.norm2(self.linear2(out))))\n",
    "        #out = self.relu3(self.gn3(self.norm3(self.linear3(out))))\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (gn0): GaussianNoise()\n",
      "  (linear1): Linear(in_features=784, out_features=1024, bias=True)\n",
      "  (norm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gn1): GaussianNoise()\n",
      "  (relu1): ReLU()\n",
      "  (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (norm2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gn2): GaussianNoise()\n",
      "  (relu2): ReLU()\n",
      "  (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the network and printing its architecture\n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-6)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=1e-6)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n",
      "[Epoch 1] LR: 0.1000 - Train Loss: 0.003335 - Test Loss: 0.001002 - Train Accuracy: 73.15% - Test Accuracy: 92.74%\n",
      "[Epoch 2] LR: 0.1000 - Train Loss: 0.001596 - Test Loss: 0.000999 - Train Accuracy: 87.53% - Test Accuracy: 92.00%\n",
      "[Epoch 3] LR: 0.1000 - Train Loss: 0.001279 - Test Loss: 0.000903 - Train Accuracy: 89.94% - Test Accuracy: 92.81%\n",
      "[Epoch 4] LR: 0.1000 - Train Loss: 0.001087 - Test Loss: 0.000492 - Train Accuracy: 91.39% - Test Accuracy: 96.18%\n",
      "[Epoch 5] LR: 0.1000 - Train Loss: 0.000986 - Test Loss: 0.000405 - Train Accuracy: 92.21% - Test Accuracy: 96.63%\n",
      "[Epoch 6] LR: 0.1000 - Train Loss: 0.000907 - Test Loss: 0.000505 - Train Accuracy: 92.79% - Test Accuracy: 95.82%\n",
      "[Epoch 7] LR: 0.1000 - Train Loss: 0.000840 - Test Loss: 0.000441 - Train Accuracy: 93.46% - Test Accuracy: 96.59%\n",
      "[Epoch 8] LR: 0.1000 - Train Loss: 0.000799 - Test Loss: 0.000382 - Train Accuracy: 93.64% - Test Accuracy: 96.91%\n",
      "[Epoch 9] LR: 0.1000 - Train Loss: 0.000760 - Test Loss: 0.000408 - Train Accuracy: 93.96% - Test Accuracy: 96.42%\n",
      "[Epoch 10] LR: 0.1000 - Train Loss: 0.000712 - Test Loss: 0.000314 - Train Accuracy: 94.33% - Test Accuracy: 97.36%\n",
      "[Epoch 11] LR: 0.1000 - Train Loss: 0.000694 - Test Loss: 0.000333 - Train Accuracy: 94.50% - Test Accuracy: 97.35%\n",
      "[Epoch 12] LR: 0.1000 - Train Loss: 0.000651 - Test Loss: 0.000332 - Train Accuracy: 94.98% - Test Accuracy: 97.00%\n",
      "[Epoch 13] LR: 0.1000 - Train Loss: 0.000626 - Test Loss: 0.000296 - Train Accuracy: 94.94% - Test Accuracy: 97.48%\n",
      "[Epoch 14] LR: 0.1000 - Train Loss: 0.000615 - Test Loss: 0.000318 - Train Accuracy: 95.12% - Test Accuracy: 97.53%\n",
      "[Epoch 15] LR: 0.1000 - Train Loss: 0.000601 - Test Loss: 0.000285 - Train Accuracy: 95.20% - Test Accuracy: 97.60%\n",
      "[Epoch 16] LR: 0.1000 - Train Loss: 0.000588 - Test Loss: 0.000279 - Train Accuracy: 95.25% - Test Accuracy: 97.74%\n",
      "[Epoch 17] LR: 0.1000 - Train Loss: 0.000554 - Test Loss: 0.000234 - Train Accuracy: 95.54% - Test Accuracy: 98.20%\n",
      "[Epoch 18] LR: 0.1000 - Train Loss: 0.000555 - Test Loss: 0.000228 - Train Accuracy: 95.72% - Test Accuracy: 98.22%\n",
      "[Epoch 19] LR: 0.1000 - Train Loss: 0.000544 - Test Loss: 0.000215 - Train Accuracy: 95.63% - Test Accuracy: 98.23%\n",
      "[Epoch 20] LR: 0.1000 - Train Loss: 0.000529 - Test Loss: 0.000274 - Train Accuracy: 95.70% - Test Accuracy: 97.61%\n",
      "[Epoch 21] LR: 0.1000 - Train Loss: 0.000511 - Test Loss: 0.000222 - Train Accuracy: 95.92% - Test Accuracy: 98.13%\n",
      "[Epoch 22] LR: 0.1000 - Train Loss: 0.000507 - Test Loss: 0.000259 - Train Accuracy: 95.92% - Test Accuracy: 97.84%\n",
      "[Epoch 23] LR: 0.1000 - Train Loss: 0.000503 - Test Loss: 0.000228 - Train Accuracy: 96.01% - Test Accuracy: 98.11%\n",
      "[Epoch 24] LR: 0.1000 - Train Loss: 0.000489 - Test Loss: 0.000194 - Train Accuracy: 96.07% - Test Accuracy: 98.47%\n",
      "[Epoch 25] LR: 0.1000 - Train Loss: 0.000470 - Test Loss: 0.000206 - Train Accuracy: 96.26% - Test Accuracy: 98.52%\n",
      "[Epoch 26] LR: 0.1000 - Train Loss: 0.000465 - Test Loss: 0.000186 - Train Accuracy: 96.29% - Test Accuracy: 98.39%\n",
      "[Epoch 27] LR: 0.1000 - Train Loss: 0.000446 - Test Loss: 0.000179 - Train Accuracy: 96.49% - Test Accuracy: 98.53%\n",
      "[Epoch 28] LR: 0.1000 - Train Loss: 0.000456 - Test Loss: 0.000185 - Train Accuracy: 96.32% - Test Accuracy: 98.52%\n",
      "[Epoch 29] LR: 0.1000 - Train Loss: 0.000448 - Test Loss: 0.000188 - Train Accuracy: 96.41% - Test Accuracy: 98.43%\n",
      "[Epoch 30] LR: 0.1000 - Train Loss: 0.000424 - Test Loss: 0.000176 - Train Accuracy: 96.61% - Test Accuracy: 98.48%\n",
      "[Epoch 31] LR: 0.1000 - Train Loss: 0.000434 - Test Loss: 0.000176 - Train Accuracy: 96.58% - Test Accuracy: 98.42%\n",
      "[Epoch 32] LR: 0.1000 - Train Loss: 0.000429 - Test Loss: 0.000177 - Train Accuracy: 96.59% - Test Accuracy: 98.52%\n",
      "[Epoch 33] LR: 0.1000 - Train Loss: 0.000419 - Test Loss: 0.000185 - Train Accuracy: 96.60% - Test Accuracy: 98.36%\n",
      "[Epoch 34] LR: 0.1000 - Train Loss: 0.000417 - Test Loss: 0.000198 - Train Accuracy: 96.72% - Test Accuracy: 98.29%\n",
      "[Epoch 35] LR: 0.1000 - Train Loss: 0.000418 - Test Loss: 0.000188 - Train Accuracy: 96.64% - Test Accuracy: 98.32%\n",
      "[Epoch 36] LR: 0.1000 - Train Loss: 0.000404 - Test Loss: 0.000172 - Train Accuracy: 96.82% - Test Accuracy: 98.56%\n",
      "[Epoch 37] LR: 0.1000 - Train Loss: 0.000386 - Test Loss: 0.000158 - Train Accuracy: 96.94% - Test Accuracy: 98.66%\n",
      "[Epoch 38] LR: 0.1000 - Train Loss: 0.000389 - Test Loss: 0.000167 - Train Accuracy: 96.81% - Test Accuracy: 98.76%\n",
      "[Epoch 39] LR: 0.1000 - Train Loss: 0.000393 - Test Loss: 0.000155 - Train Accuracy: 96.88% - Test Accuracy: 98.64%\n",
      "[Epoch 40] LR: 0.1000 - Train Loss: 0.000382 - Test Loss: 0.000149 - Train Accuracy: 96.94% - Test Accuracy: 98.69%\n",
      "[Epoch 41] LR: 0.1000 - Train Loss: 0.000385 - Test Loss: 0.000153 - Train Accuracy: 96.96% - Test Accuracy: 98.69%\n",
      "[Epoch 42] LR: 0.1000 - Train Loss: 0.000382 - Test Loss: 0.000163 - Train Accuracy: 96.91% - Test Accuracy: 98.64%\n",
      "[Epoch 43] LR: 0.1000 - Train Loss: 0.000368 - Test Loss: 0.000197 - Train Accuracy: 97.01% - Test Accuracy: 98.35%\n",
      "[Epoch 44] LR: 0.1000 - Train Loss: 0.000368 - Test Loss: 0.000147 - Train Accuracy: 96.97% - Test Accuracy: 98.71%\n",
      "[Epoch 45] LR: 0.1000 - Train Loss: 0.000367 - Test Loss: 0.000147 - Train Accuracy: 97.07% - Test Accuracy: 98.77%\n",
      "[Epoch 46] LR: 0.1000 - Train Loss: 0.000365 - Test Loss: 0.000141 - Train Accuracy: 97.07% - Test Accuracy: 98.75%\n",
      "[Epoch 47] LR: 0.1000 - Train Loss: 0.000363 - Test Loss: 0.000141 - Train Accuracy: 97.04% - Test Accuracy: 98.88%\n",
      "[Epoch 48] LR: 0.1000 - Train Loss: 0.000359 - Test Loss: 0.000128 - Train Accuracy: 97.05% - Test Accuracy: 98.89%\n",
      "[Epoch 49] LR: 0.1000 - Train Loss: 0.000346 - Test Loss: 0.000124 - Train Accuracy: 97.25% - Test Accuracy: 98.95%\n",
      "[Epoch 50] LR: 0.1000 - Train Loss: 0.000348 - Test Loss: 0.000143 - Train Accuracy: 97.18% - Test Accuracy: 98.80%\n",
      "[Epoch 51] LR: 0.1000 - Train Loss: 0.000337 - Test Loss: 0.000152 - Train Accuracy: 97.24% - Test Accuracy: 98.79%\n",
      "[Epoch 52] LR: 0.1000 - Train Loss: 0.000338 - Test Loss: 0.000154 - Train Accuracy: 97.34% - Test Accuracy: 98.76%\n",
      "[Epoch 53] LR: 0.1000 - Train Loss: 0.000340 - Test Loss: 0.000129 - Train Accuracy: 97.21% - Test Accuracy: 98.80%\n",
      "[Epoch 54] LR: 0.1000 - Train Loss: 0.000339 - Test Loss: 0.000133 - Train Accuracy: 97.31% - Test Accuracy: 98.85%\n",
      "[Epoch 55] LR: 0.1000 - Train Loss: 0.000322 - Test Loss: 0.000147 - Train Accuracy: 97.42% - Test Accuracy: 98.74%\n",
      "[Epoch 56] LR: 0.0100 - Train Loss: 0.000310 - Test Loss: 0.000116 - Train Accuracy: 97.52% - Test Accuracy: 98.89%\n",
      "[Epoch 57] LR: 0.0100 - Train Loss: 0.000292 - Test Loss: 0.000107 - Train Accuracy: 97.66% - Test Accuracy: 99.07%\n",
      "[Epoch 58] LR: 0.0100 - Train Loss: 0.000284 - Test Loss: 0.000109 - Train Accuracy: 97.73% - Test Accuracy: 99.06%\n",
      "[Epoch 59] LR: 0.0100 - Train Loss: 0.000276 - Test Loss: 0.000107 - Train Accuracy: 97.77% - Test Accuracy: 99.05%\n",
      "[Epoch 60] LR: 0.0100 - Train Loss: 0.000282 - Test Loss: 0.000108 - Train Accuracy: 97.78% - Test Accuracy: 99.15%\n",
      "[Epoch 61] LR: 0.0100 - Train Loss: 0.000271 - Test Loss: 0.000109 - Train Accuracy: 97.76% - Test Accuracy: 99.10%\n",
      "[Epoch 62] LR: 0.0100 - Train Loss: 0.000274 - Test Loss: 0.000110 - Train Accuracy: 97.79% - Test Accuracy: 99.15%\n",
      "[Epoch 63] LR: 0.0100 - Train Loss: 0.000260 - Test Loss: 0.000109 - Train Accuracy: 97.97% - Test Accuracy: 99.10%\n",
      "[Epoch 64] LR: 0.0010 - Train Loss: 0.000269 - Test Loss: 0.000101 - Train Accuracy: 97.87% - Test Accuracy: 99.12%\n",
      "[Epoch 65] LR: 0.0010 - Train Loss: 0.000261 - Test Loss: 0.000100 - Train Accuracy: 97.97% - Test Accuracy: 99.16%\n",
      "[Epoch 66] LR: 0.0010 - Train Loss: 0.000265 - Test Loss: 0.000101 - Train Accuracy: 97.88% - Test Accuracy: 99.12%\n",
      "[Epoch 67] LR: 0.0010 - Train Loss: 0.000259 - Test Loss: 0.000100 - Train Accuracy: 97.89% - Test Accuracy: 99.18%\n",
      "[Epoch 68] LR: 0.0010 - Train Loss: 0.000271 - Test Loss: 0.000104 - Train Accuracy: 97.87% - Test Accuracy: 99.19%\n",
      "[Epoch 69] LR: 0.0010 - Train Loss: 0.000258 - Test Loss: 0.000100 - Train Accuracy: 97.91% - Test Accuracy: 99.16%\n",
      "[Epoch 70] LR: 0.0010 - Train Loss: 0.000261 - Test Loss: 0.000099 - Train Accuracy: 97.97% - Test Accuracy: 99.14%\n",
      "[Epoch 71] LR: 0.0010 - Train Loss: 0.000264 - Test Loss: 0.000103 - Train Accuracy: 97.92% - Test Accuracy: 99.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72] LR: 0.0010 - Train Loss: 0.000264 - Test Loss: 0.000098 - Train Accuracy: 97.89% - Test Accuracy: 99.17%\n",
      "[Epoch 73] LR: 0.0010 - Train Loss: 0.000263 - Test Loss: 0.000099 - Train Accuracy: 97.90% - Test Accuracy: 99.15%\n",
      "[Epoch 74] LR: 0.0010 - Train Loss: 0.000260 - Test Loss: 0.000098 - Train Accuracy: 97.89% - Test Accuracy: 99.10%\n",
      "[Epoch 75] LR: 0.0010 - Train Loss: 0.000263 - Test Loss: 0.000099 - Train Accuracy: 97.93% - Test Accuracy: 99.20%\n",
      "[Epoch 76] LR: 0.0010 - Train Loss: 0.000262 - Test Loss: 0.000098 - Train Accuracy: 97.89% - Test Accuracy: 99.19%\n",
      "[Epoch 77] LR: 0.0010 - Train Loss: 0.000261 - Test Loss: 0.000098 - Train Accuracy: 97.91% - Test Accuracy: 99.15%\n",
      "[Epoch 78] LR: 0.0010 - Train Loss: 0.000252 - Test Loss: 0.000100 - Train Accuracy: 98.00% - Test Accuracy: 99.13%\n",
      "[Epoch 79] LR: 0.0010 - Train Loss: 0.000264 - Test Loss: 0.000098 - Train Accuracy: 97.92% - Test Accuracy: 99.20%\n",
      "[Epoch 80] LR: 0.0010 - Train Loss: 0.000254 - Test Loss: 0.000099 - Train Accuracy: 97.98% - Test Accuracy: 99.14%\n",
      "[Epoch 81] LR: 0.0010 - Train Loss: 0.000254 - Test Loss: 0.000103 - Train Accuracy: 98.00% - Test Accuracy: 99.15%\n",
      "[Epoch 82] LR: 0.0010 - Train Loss: 0.000260 - Test Loss: 0.000098 - Train Accuracy: 97.97% - Test Accuracy: 99.15%\n",
      "[Epoch 83] LR: 0.0010 - Train Loss: 0.000258 - Test Loss: 0.000101 - Train Accuracy: 97.91% - Test Accuracy: 99.14%\n",
      "[Epoch 84] LR: 0.0010 - Train Loss: 0.000259 - Test Loss: 0.000099 - Train Accuracy: 97.98% - Test Accuracy: 99.13%\n",
      "[Epoch 85] LR: 0.0010 - Train Loss: 0.000262 - Test Loss: 0.000098 - Train Accuracy: 97.94% - Test Accuracy: 99.19%\n",
      "[Epoch 86] LR: 0.0001 - Train Loss: 0.000249 - Test Loss: 0.000099 - Train Accuracy: 97.95% - Test Accuracy: 99.17%\n",
      "[Epoch 87] LR: 0.0001 - Train Loss: 0.000263 - Test Loss: 0.000098 - Train Accuracy: 97.87% - Test Accuracy: 99.16%\n",
      "[Epoch 88] LR: 0.0001 - Train Loss: 0.000262 - Test Loss: 0.000118 - Train Accuracy: 97.99% - Test Accuracy: 99.14%\n",
      "[Epoch 89] LR: 0.0001 - Train Loss: 0.000266 - Test Loss: 0.000100 - Train Accuracy: 97.89% - Test Accuracy: 99.17%\n",
      "[Epoch 90] LR: 0.0001 - Train Loss: 0.000269 - Test Loss: 0.000108 - Train Accuracy: 97.86% - Test Accuracy: 99.20%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-871206eacaa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"\\n---- Start Training ----\")\n",
    "best_accuracy = -1\n",
    "for i in range(epochs):\n",
    "\n",
    "    # TRAIN THE NETWORK\n",
    "    train_loss, train_correct = 0, 0\n",
    "    net.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # care! net expect a 784 size vector and our dataset provide 1x28x28 (channels, height, width) -> Reshape!\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "        train_correct += pred.eq(targets).sum().item()\n",
    "\n",
    "        # print statistics\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # TEST NETWORK\n",
    "    net.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            # care! net expect a 784 size vector and our dataset provide 1x28x28 (channels, height, width) -> Reshape!\n",
    "            inputs = inputs.view(inputs.size(0), -1)\n",
    "            outputs = net(inputs)\n",
    "            test_loss += criterion(outputs, targets)\n",
    "            _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    # Get current learning rate via the optimizer\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "    \n",
    "    print(\"[Epoch {}] LR: {:.4f} - Train Loss: {:.6f} - Test Loss: {:.6f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(\n",
    "            epoch + 1, current_lr, train_loss, test_loss, 100. * train_correct / len(train_loader.dataset), test_accuracy\n",
    "        ))\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        \n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    epoch += 1\n",
    "\n",
    "print(\"Finished Training\")\n",
    "print(\"Best Test accuracy: {:.2f}%\".format(best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./models/mnist_mlp_param_state.pt\")\n",
    "torch.save(optimizer.state_dict(), \"./models/mnist_mlp_optim_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
