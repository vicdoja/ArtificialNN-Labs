{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Constants definition\n",
    "batch_size = 128\n",
    "epochs = 300\n",
    "num_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Creating dataloaders\n",
    "data_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomAffine(degrees=5, translate=(0.010, 0.005), scale=(0.995, 1.005)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10('.data/', train=True, download=True, transform=data_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10('.data/', train=False, download=True, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 50000 samples - Max value: 1.0 - Min value: -1.0\n",
      "Test set: 10000 samples - Max value: 1.0 - Min value: -1.0\n",
      "Example batch shape: torch.Size([128, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Statistics printing\n",
    "x_batch, y_batch = iter(train_loader).next()\n",
    "print(\"Training set: {} samples - Max value: {} - Min value: {}\".format(len(train_loader.dataset),\n",
    "                                                                        x_batch.max(), x_batch.min()))\n",
    "x_batch, y_batch = iter(test_loader).next()\n",
    "print(\"Test set: {} samples - Max value: {} - Min value: {}\".format(len(test_loader.dataset),\n",
    "                                                                    x_batch.max(), x_batch.min()))\n",
    "print(\"Example batch shape: {}\".format(x_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our Neural Network - PreActResNet18\n",
    "class PreActResNet18(nn.Module):\n",
    "    class IdentityBlock(nn.Module):\n",
    "        \"\"\"Residual network block.\n",
    "        Args:\n",
    "            channels (int): number of channels.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, channels):\n",
    "            super().__init__()\n",
    "\n",
    "            self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(channels)\n",
    "            self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = F.relu(self.bn1(x))\n",
    "            out = self.conv1(out)\n",
    "            out = self.conv2(F.relu(self.bn2(out)))\n",
    "            out = x + out  # resnet connection\n",
    "\n",
    "            return out\n",
    "\n",
    "    class ConvBlock(nn.Module):\n",
    "        \"\"\"Residual network block.\n",
    "        Args:\n",
    "            channels (int): number of channels.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, channels):\n",
    "            super().__init__()\n",
    "\n",
    "            self.conv_s = nn.Conv2d(channels//2, channels, kernel_size=1, stride=2, bias=False)\n",
    "\n",
    "            self.conv1 = nn.Conv2d(channels//2, channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(channels//2)\n",
    "            self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = F.relu(self.bn1(x))\n",
    "            short = self.conv_s(out)\n",
    "            out = self.conv1(out)\n",
    "            out = self.conv2(F.relu(self.bn2(out)))\n",
    "            out = short + out  # resnet connection\n",
    "\n",
    "            return out\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(PreActResNet18, self).__init__()\n",
    "        # Initial convolution before resnet blocks\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        \n",
    "        convs = list(zip([3, 4, 6, 3],[64*(2**i) for i in range(4)]))\n",
    "        for _ in range(convs[0][0]):\n",
    "            self.blocks.append(self.IdentityBlock(convs[0][1]))\n",
    "        for i, chs in convs[1:]:\n",
    "            self.blocks.append(self.ConvBlock(chs))\n",
    "            for _ in range(i-1):\n",
    "                self.blocks.append(self.IdentityBlock(chs))\n",
    "\n",
    "        ########## 1x1@512\n",
    "        # Final pooling\n",
    "        self.average_pooling = nn.AvgPool2d(4)\n",
    "\n",
    "        ########## 512@num_classes\n",
    "        # To connect to the number of classes\n",
    "        self.out_layer = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #### 32x32@3 -> 32x32@64\n",
    "        # 0. Initial convolution ==> \n",
    "        initial_conv = self.conv1(x)\n",
    "        \n",
    "        res_out = initial_conv\n",
    "        for b in self.blocks:\n",
    "            res_out = b(res_out)\n",
    "\n",
    "        #### 4x4@512 -> 1x1@512\n",
    "        #print(res_out.shape)\n",
    "        pool_out = self.average_pooling(res_out)\n",
    "        #print(pool_out.shape)\n",
    "        \n",
    "        #### 512 -> num_classes\n",
    "        fc_out = self.out_layer(pool_out.view(pool_out.size(0), -1))\n",
    "\n",
    "        return fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreActResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0): IdentityBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): IdentityBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): IdentityBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (conv_s): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): IdentityBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): IdentityBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): IdentityBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ConvBlock(\n",
      "      (conv_s): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): IdentityBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): IdentityBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): IdentityBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): IdentityBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): IdentityBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): ConvBlock(\n",
      "      (conv_s): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): IdentityBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): IdentityBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (average_pooling): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (out_layer): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the network and printing its architecture\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "net = PreActResNet18()\n",
    "net = net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-6)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=1e-6)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n",
      "[Epoch 1] LR: 0.1000 - Train Loss: 0.015390 - Test Loss: 0.014825 - Train Accuracy: 30.64% - Test Accuracy: 34.46%\n",
      "[Epoch 2] LR: 0.1000 - Train Loss: 0.011535 - Test Loss: 0.011483 - Train Accuracy: 46.24% - Test Accuracy: 47.55%\n",
      "[Epoch 3] LR: 0.1000 - Train Loss: 0.009588 - Test Loss: 0.009729 - Train Accuracy: 55.97% - Test Accuracy: 56.54%\n",
      "[Epoch 4] LR: 0.1000 - Train Loss: 0.008003 - Test Loss: 0.008344 - Train Accuracy: 63.65% - Test Accuracy: 64.20%\n",
      "[Epoch 5] LR: 0.1000 - Train Loss: 0.006832 - Test Loss: 0.008688 - Train Accuracy: 69.27% - Test Accuracy: 66.58%\n",
      "[Epoch 6] LR: 0.1000 - Train Loss: 0.005844 - Test Loss: 0.007865 - Train Accuracy: 74.11% - Test Accuracy: 67.91%\n",
      "[Epoch 7] LR: 0.1000 - Train Loss: 0.005190 - Test Loss: 0.007386 - Train Accuracy: 76.93% - Test Accuracy: 70.37%\n",
      "[Epoch 8] LR: 0.1000 - Train Loss: 0.004613 - Test Loss: 0.005978 - Train Accuracy: 79.54% - Test Accuracy: 74.52%\n",
      "[Epoch 9] LR: 0.1000 - Train Loss: 0.004246 - Test Loss: 0.005978 - Train Accuracy: 81.14% - Test Accuracy: 74.97%\n",
      "[Epoch 10] LR: 0.1000 - Train Loss: 0.003891 - Test Loss: 0.005264 - Train Accuracy: 82.83% - Test Accuracy: 78.71%\n",
      "[Epoch 11] LR: 0.1000 - Train Loss: 0.003562 - Test Loss: 0.004592 - Train Accuracy: 84.31% - Test Accuracy: 81.04%\n",
      "[Epoch 12] LR: 0.1000 - Train Loss: 0.003284 - Test Loss: 0.004574 - Train Accuracy: 85.40% - Test Accuracy: 81.79%\n",
      "[Epoch 13] LR: 0.1000 - Train Loss: 0.003061 - Test Loss: 0.004991 - Train Accuracy: 86.46% - Test Accuracy: 80.10%\n",
      "[Epoch 14] LR: 0.1000 - Train Loss: 0.002867 - Test Loss: 0.004235 - Train Accuracy: 87.22% - Test Accuracy: 82.57%\n",
      "[Epoch 15] LR: 0.1000 - Train Loss: 0.002638 - Test Loss: 0.005053 - Train Accuracy: 88.31% - Test Accuracy: 79.89%\n",
      "[Epoch 16] LR: 0.1000 - Train Loss: 0.002500 - Test Loss: 0.005187 - Train Accuracy: 88.84% - Test Accuracy: 79.97%\n",
      "[Epoch 17] LR: 0.1000 - Train Loss: 0.002355 - Test Loss: 0.003665 - Train Accuracy: 89.52% - Test Accuracy: 85.04%\n",
      "[Epoch 18] LR: 0.1000 - Train Loss: 0.002217 - Test Loss: 0.003564 - Train Accuracy: 90.22% - Test Accuracy: 85.75%\n",
      "[Epoch 19] LR: 0.1000 - Train Loss: 0.002083 - Test Loss: 0.003460 - Train Accuracy: 90.75% - Test Accuracy: 86.40%\n",
      "[Epoch 20] LR: 0.1000 - Train Loss: 0.001955 - Test Loss: 0.004775 - Train Accuracy: 91.21% - Test Accuracy: 82.20%\n",
      "[Epoch 21] LR: 0.1000 - Train Loss: 0.001858 - Test Loss: 0.003825 - Train Accuracy: 91.75% - Test Accuracy: 85.50%\n",
      "[Epoch 22] LR: 0.1000 - Train Loss: 0.001747 - Test Loss: 0.003591 - Train Accuracy: 92.21% - Test Accuracy: 86.79%\n",
      "[Epoch 23] LR: 0.1000 - Train Loss: 0.001664 - Test Loss: 0.004155 - Train Accuracy: 92.58% - Test Accuracy: 84.30%\n",
      "[Epoch 24] LR: 0.1000 - Train Loss: 0.001565 - Test Loss: 0.003300 - Train Accuracy: 92.96% - Test Accuracy: 88.18%\n",
      "[Epoch 25] LR: 0.1000 - Train Loss: 0.001524 - Test Loss: 0.002772 - Train Accuracy: 93.21% - Test Accuracy: 89.48%\n",
      "[Epoch 26] LR: 0.1000 - Train Loss: 0.001389 - Test Loss: 0.003093 - Train Accuracy: 93.76% - Test Accuracy: 88.65%\n",
      "[Epoch 27] LR: 0.1000 - Train Loss: 0.001353 - Test Loss: 0.002891 - Train Accuracy: 93.90% - Test Accuracy: 89.07%\n",
      "[Epoch 28] LR: 0.1000 - Train Loss: 0.001270 - Test Loss: 0.003138 - Train Accuracy: 94.30% - Test Accuracy: 88.63%\n",
      "[Epoch 29] LR: 0.1000 - Train Loss: 0.001220 - Test Loss: 0.003347 - Train Accuracy: 94.54% - Test Accuracy: 87.73%\n",
      "[Epoch 30] LR: 0.1000 - Train Loss: 0.001168 - Test Loss: 0.003421 - Train Accuracy: 94.73% - Test Accuracy: 88.15%\n",
      "[Epoch 31] LR: 0.1000 - Train Loss: 0.001086 - Test Loss: 0.002780 - Train Accuracy: 95.14% - Test Accuracy: 89.88%\n",
      "[Epoch 32] LR: 0.0100 - Train Loss: 0.000607 - Test Loss: 0.002234 - Train Accuracy: 97.34% - Test Accuracy: 91.91%\n",
      "[Epoch 33] LR: 0.0100 - Train Loss: 0.000475 - Test Loss: 0.002334 - Train Accuracy: 97.94% - Test Accuracy: 92.23%\n",
      "[Epoch 34] LR: 0.0100 - Train Loss: 0.000416 - Test Loss: 0.002358 - Train Accuracy: 98.15% - Test Accuracy: 92.28%\n",
      "[Epoch 35] LR: 0.0100 - Train Loss: 0.000390 - Test Loss: 0.002456 - Train Accuracy: 98.22% - Test Accuracy: 92.30%\n",
      "[Epoch 36] LR: 0.0100 - Train Loss: 0.000369 - Test Loss: 0.002411 - Train Accuracy: 98.37% - Test Accuracy: 92.28%\n",
      "[Epoch 37] LR: 0.0100 - Train Loss: 0.000327 - Test Loss: 0.002539 - Train Accuracy: 98.57% - Test Accuracy: 92.31%\n",
      "[Epoch 38] LR: 0.0100 - Train Loss: 0.000306 - Test Loss: 0.002549 - Train Accuracy: 98.67% - Test Accuracy: 92.38%\n",
      "[Epoch 39] LR: 0.0010 - Train Loss: 0.000288 - Test Loss: 0.002665 - Train Accuracy: 98.73% - Test Accuracy: 92.37%\n",
      "[Epoch 40] LR: 0.0010 - Train Loss: 0.000274 - Test Loss: 0.002606 - Train Accuracy: 98.78% - Test Accuracy: 92.43%\n",
      "[Epoch 41] LR: 0.0010 - Train Loss: 0.000268 - Test Loss: 0.002562 - Train Accuracy: 98.84% - Test Accuracy: 92.45%\n",
      "[Epoch 42] LR: 0.0010 - Train Loss: 0.000262 - Test Loss: 0.002579 - Train Accuracy: 98.85% - Test Accuracy: 92.45%\n",
      "[Epoch 43] LR: 0.0010 - Train Loss: 0.000275 - Test Loss: 0.002582 - Train Accuracy: 98.83% - Test Accuracy: 92.46%\n",
      "[Epoch 44] LR: 0.0010 - Train Loss: 0.000271 - Test Loss: 0.002670 - Train Accuracy: 98.75% - Test Accuracy: 92.40%\n",
      "[Epoch 45] LR: 0.0001 - Train Loss: 0.000260 - Test Loss: 0.002599 - Train Accuracy: 98.84% - Test Accuracy: 92.43%\n",
      "[Epoch 46] LR: 0.0001 - Train Loss: 0.000267 - Test Loss: 0.002643 - Train Accuracy: 98.82% - Test Accuracy: 92.40%\n",
      "[Epoch 47] LR: 0.0001 - Train Loss: 0.000257 - Test Loss: 0.002601 - Train Accuracy: 98.87% - Test Accuracy: 92.43%\n",
      "[Epoch 48] LR: 0.0001 - Train Loss: 0.000269 - Test Loss: 0.002564 - Train Accuracy: 98.83% - Test Accuracy: 92.47%\n",
      "[Epoch 49] LR: 0.0001 - Train Loss: 0.000273 - Test Loss: 0.002616 - Train Accuracy: 98.85% - Test Accuracy: 92.45%\n",
      "[Epoch 50] LR: 0.0001 - Train Loss: 0.000281 - Test Loss: 0.002568 - Train Accuracy: 98.78% - Test Accuracy: 92.41%\n",
      "[Epoch 51] LR: 0.0000 - Train Loss: 0.000266 - Test Loss: 0.002591 - Train Accuracy: 98.86% - Test Accuracy: 92.44%\n",
      "[Epoch 52] LR: 0.0000 - Train Loss: 0.000270 - Test Loss: 0.002742 - Train Accuracy: 98.77% - Test Accuracy: 92.35%\n",
      "[Epoch 53] LR: 0.0000 - Train Loss: 0.000265 - Test Loss: 0.002644 - Train Accuracy: 98.87% - Test Accuracy: 92.43%\n",
      "[Epoch 54] LR: 0.0000 - Train Loss: 0.000263 - Test Loss: 0.002595 - Train Accuracy: 98.86% - Test Accuracy: 92.46%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-316ff10832d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtrain_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"\\n---- Start Training ----\")\n",
    "best_accuracy = -1\n",
    "for i in range(epochs):\n",
    "\n",
    "    # TRAIN THE NETWORK\n",
    "    train_loss, train_correct = 0, 0\n",
    "    net.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "        train_correct += pred.eq(targets).sum().item()\n",
    "\n",
    "        # print statistics\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # TEST NETWORK\n",
    "    net.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            test_loss += criterion(outputs, targets)\n",
    "            _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    # Get current learning rate via the optimizer\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "    \n",
    "    print(\"[Epoch {}] LR: {:.4f} - Train Loss: {:.6f} - Test Loss: {:.6f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(\n",
    "            epoch + 1, current_lr, train_loss, test_loss, 100. * train_correct / len(train_loader.dataset), test_accuracy\n",
    "        ))\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        \n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    epoch += 1\n",
    "\n",
    "print(\"Finished Training\")\n",
    "print(\"Best Test accuracy: {:.2f}%\".format(best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./models/cifar_preact_resnet_param_state.pt\")\n",
    "torch.save(optimizer.state_dict(), \"./models/cifar_preact_resnet_optim_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
