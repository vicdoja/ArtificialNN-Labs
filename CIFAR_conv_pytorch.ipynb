{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Constants definition\n",
    "batch_size = 200\n",
    "epochs = 200\n",
    "num_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Creating dataloaders\n",
    "# ToTensor() - Converts a Image (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "data_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomAffine(degrees=90, translate=(0.1, 0.1), scale=(1.1, 1.1)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10('.data/', train=True, download=True, transform=data_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10('.data/', train=False, download=True, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 50000 samples - Max value: 1.0 - Min value: -1.0\n",
      "Test set: 10000 samples - Max value: 1.0 - Min value: -1.0\n",
      "Example batch shape: torch.Size([200, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Statistics printing\n",
    "x_batch, y_batch = iter(train_loader).next()\n",
    "print(\"Training set: {} samples - Max value: {} - Min value: {}\".format(len(train_loader.dataset),\n",
    "                                                                        x_batch.max(), x_batch.min()))\n",
    "x_batch, y_batch = iter(test_loader).next()\n",
    "print(\"Test set: {} samples - Max value: {} - Min value: {}\".format(len(test_loader.dataset),\n",
    "                                                                    x_batch.max(), x_batch.min()))\n",
    "print(\"Example batch shape: {}\".format(x_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no GaussianNoise Layer in Pytorch\n",
    "# https://discuss.pytorch.org/t/writing-a-simple-gaussian-noise-layer-in-pytorch/4694/4\n",
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.noise = torch.tensor(0).to(device).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x\n",
    "    \n",
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"Residual network block.\n",
    "    Args:\n",
    "        channels (int): number of channels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        '''self.conv3 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(channels)'''\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''out = F.elu(self.bn1(self.conv1(x)))\n",
    "        out = F.elu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = F.elu(x + out)  # resnet connection plus activation'''\n",
    "        out = F.elu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = F.elu(x + out)  # resnet connection plus activation\n",
    "        return out\n",
    "    \n",
    "class ReducingBlock(nn.Module):\n",
    "    \"\"\"Dimension reducer block.\n",
    "    Args:\n",
    "        inp_channels (int): number of input channels.\n",
    "        out_channels (int): number of output channels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inp_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(inp_channels, out_channels, kernel_size=1, stride=2, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn(self.conv(x))\n",
    "        return out\n",
    "\n",
    "# Creating our Neural Network - ResNet18\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, n_reductions=4, n_convs=4):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        # Initial convolution before resnet blocks\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        \n",
    "        for chan in [64*(2**i) for i in range(n_reductions-1)]:\n",
    "            for conv in range(n_convs):\n",
    "                self.blocks.append(ResNetBlock(chan))\n",
    "            self.blocks.append(ReducingBlock(chan, chan*2))\n",
    "            self.blocks.append(nn.Dropout2d(p=0.1))\n",
    "        for conv in range(n_convs):\n",
    "            self.blocks.append(ResNetBlock(64*(2**(n_reductions-1))))\n",
    "\n",
    "        ########## 1x1@512\n",
    "        # Final pooling\n",
    "        self.average_pooling = nn.AvgPool2d(4)\n",
    "\n",
    "        ########## 512@num_classes\n",
    "        # To connect to the number of classes\n",
    "        self.linear = nn.Linear(64*(2**(n_reductions-1)), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #### 32x32@3 -> 32x32@64\n",
    "        # 0. Initial convolution ==> \n",
    "        initial_conv = F.elu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        res_out = initial_conv\n",
    "        for b in self.blocks:\n",
    "            res_out = b(res_out)\n",
    "\n",
    "        #### 4x4@512 -> 1x1@512\n",
    "        pool_out = self.average_pooling(res_out)\n",
    "\n",
    "        #### 512 -> num_classes\n",
    "        fc_out = self.linear(pool_out.view(pool_out.size(0), -1))\n",
    "\n",
    "        return fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (blocks): ModuleList(\n",
      "    (0): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ReducingBlock(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): Dropout2d(p=0.1, inplace=False)\n",
      "    (6): ResNetBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ResNetBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): ResNetBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): ResNetBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): ReducingBlock(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): Dropout2d(p=0.1, inplace=False)\n",
      "    (12): ResNetBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): ResNetBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): ResNetBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): ResNetBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): ReducingBlock(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): Dropout2d(p=0.1, inplace=False)\n",
      "    (18): ResNetBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (19): ResNetBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (20): ResNetBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (21): ResNetBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (average_pooling): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the network and printing its architecture\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "net = CustomResNet()\n",
    "net = net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1, weight_decay=1e-6)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=1e-4, momentum=0.9)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n",
      "[Epoch 1] LR: 0.1000 - Train Loss: 0.013802 - Test Loss: 0.009636 - Train Accuracy: 20.77% - Test Accuracy: 28.46%\n",
      "[Epoch 2] LR: 0.1000 - Train Loss: 0.009595 - Test Loss: 0.009275 - Train Accuracy: 29.00% - Test Accuracy: 30.58%\n",
      "[Epoch 3] LR: 0.1000 - Train Loss: 0.009080 - Test Loss: 0.008608 - Train Accuracy: 33.65% - Test Accuracy: 35.90%\n",
      "[Epoch 4] LR: 0.1000 - Train Loss: 0.008755 - Test Loss: 0.008382 - Train Accuracy: 35.84% - Test Accuracy: 38.82%\n",
      "[Epoch 5] LR: 0.1000 - Train Loss: 0.008476 - Test Loss: 0.008117 - Train Accuracy: 38.52% - Test Accuracy: 40.88%\n",
      "[Epoch 6] LR: 0.1000 - Train Loss: 0.008271 - Test Loss: 0.007973 - Train Accuracy: 39.84% - Test Accuracy: 42.10%\n",
      "[Epoch 7] LR: 0.1000 - Train Loss: 0.008014 - Test Loss: 0.007674 - Train Accuracy: 42.02% - Test Accuracy: 44.92%\n",
      "[Epoch 8] LR: 0.1000 - Train Loss: 0.007784 - Test Loss: 0.007958 - Train Accuracy: 43.40% - Test Accuracy: 44.02%\n",
      "[Epoch 9] LR: 0.1000 - Train Loss: 0.007520 - Test Loss: 0.007327 - Train Accuracy: 45.71% - Test Accuracy: 48.12%\n",
      "[Epoch 10] LR: 0.1000 - Train Loss: 0.007290 - Test Loss: 0.006971 - Train Accuracy: 47.36% - Test Accuracy: 50.00%\n",
      "[Epoch 11] LR: 0.1000 - Train Loss: 0.007022 - Test Loss: 0.006581 - Train Accuracy: 49.55% - Test Accuracy: 52.81%\n",
      "[Epoch 12] LR: 0.1000 - Train Loss: 0.006838 - Test Loss: 0.007066 - Train Accuracy: 50.90% - Test Accuracy: 49.37%\n",
      "[Epoch 13] LR: 0.1000 - Train Loss: 0.006661 - Test Loss: 0.006463 - Train Accuracy: 52.26% - Test Accuracy: 54.63%\n",
      "[Epoch 14] LR: 0.1000 - Train Loss: 0.006566 - Test Loss: 0.006716 - Train Accuracy: 52.97% - Test Accuracy: 52.63%\n",
      "[Epoch 15] LR: 0.1000 - Train Loss: 0.006427 - Test Loss: 0.006079 - Train Accuracy: 53.87% - Test Accuracy: 56.93%\n",
      "[Epoch 16] LR: 0.1000 - Train Loss: 0.006270 - Test Loss: 0.005961 - Train Accuracy: 55.22% - Test Accuracy: 58.14%\n",
      "[Epoch 17] LR: 0.1000 - Train Loss: 0.006132 - Test Loss: 0.005917 - Train Accuracy: 56.03% - Test Accuracy: 57.83%\n",
      "[Epoch 18] LR: 0.1000 - Train Loss: 0.005982 - Test Loss: 0.005608 - Train Accuracy: 57.51% - Test Accuracy: 60.05%\n",
      "[Epoch 19] LR: 0.1000 - Train Loss: 0.005857 - Test Loss: 0.005618 - Train Accuracy: 58.11% - Test Accuracy: 60.14%\n",
      "[Epoch 20] LR: 0.1000 - Train Loss: 0.005681 - Test Loss: 0.005483 - Train Accuracy: 59.28% - Test Accuracy: 60.08%\n",
      "[Epoch 21] LR: 0.1000 - Train Loss: 0.005530 - Test Loss: 0.005195 - Train Accuracy: 60.70% - Test Accuracy: 63.78%\n",
      "[Epoch 22] LR: 0.1000 - Train Loss: 0.005397 - Test Loss: 0.005650 - Train Accuracy: 61.60% - Test Accuracy: 60.98%\n",
      "[Epoch 23] LR: 0.1000 - Train Loss: 0.005275 - Test Loss: 0.005528 - Train Accuracy: 62.49% - Test Accuracy: 61.40%\n",
      "[Epoch 24] LR: 0.1000 - Train Loss: 0.005139 - Test Loss: 0.004782 - Train Accuracy: 63.63% - Test Accuracy: 66.71%\n",
      "[Epoch 25] LR: 0.1000 - Train Loss: 0.005027 - Test Loss: 0.004794 - Train Accuracy: 64.34% - Test Accuracy: 66.52%\n",
      "[Epoch 26] LR: 0.1000 - Train Loss: 0.004906 - Test Loss: 0.004736 - Train Accuracy: 65.40% - Test Accuracy: 66.48%\n",
      "[Epoch 27] LR: 0.1000 - Train Loss: 0.004826 - Test Loss: 0.004458 - Train Accuracy: 65.97% - Test Accuracy: 68.69%\n",
      "[Epoch 28] LR: 0.1000 - Train Loss: 0.004741 - Test Loss: 0.004626 - Train Accuracy: 66.58% - Test Accuracy: 67.45%\n",
      "[Epoch 29] LR: 0.1000 - Train Loss: 0.004689 - Test Loss: 0.004682 - Train Accuracy: 66.94% - Test Accuracy: 67.74%\n",
      "[Epoch 30] LR: 0.1000 - Train Loss: 0.004611 - Test Loss: 0.004331 - Train Accuracy: 67.66% - Test Accuracy: 70.06%\n",
      "[Epoch 31] LR: 0.1000 - Train Loss: 0.004518 - Test Loss: 0.004299 - Train Accuracy: 68.08% - Test Accuracy: 70.44%\n",
      "[Epoch 32] LR: 0.1000 - Train Loss: 0.004435 - Test Loss: 0.004358 - Train Accuracy: 68.71% - Test Accuracy: 69.05%\n",
      "[Epoch 33] LR: 0.1000 - Train Loss: 0.004374 - Test Loss: 0.004033 - Train Accuracy: 69.33% - Test Accuracy: 72.19%\n",
      "[Epoch 34] LR: 0.1000 - Train Loss: 0.004291 - Test Loss: 0.003968 - Train Accuracy: 69.91% - Test Accuracy: 72.51%\n",
      "[Epoch 35] LR: 0.1000 - Train Loss: 0.004218 - Test Loss: 0.004003 - Train Accuracy: 70.48% - Test Accuracy: 72.21%\n",
      "[Epoch 36] LR: 0.1000 - Train Loss: 0.004169 - Test Loss: 0.003924 - Train Accuracy: 70.79% - Test Accuracy: 72.82%\n",
      "[Epoch 37] LR: 0.1000 - Train Loss: 0.004133 - Test Loss: 0.004019 - Train Accuracy: 71.21% - Test Accuracy: 72.25%\n",
      "[Epoch 38] LR: 0.1000 - Train Loss: 0.004104 - Test Loss: 0.003709 - Train Accuracy: 71.33% - Test Accuracy: 73.89%\n",
      "[Epoch 39] LR: 0.1000 - Train Loss: 0.004049 - Test Loss: 0.003816 - Train Accuracy: 71.60% - Test Accuracy: 74.02%\n",
      "[Epoch 40] LR: 0.1000 - Train Loss: 0.003959 - Test Loss: 0.003635 - Train Accuracy: 72.27% - Test Accuracy: 74.61%\n",
      "[Epoch 41] LR: 0.1000 - Train Loss: 0.003940 - Test Loss: 0.003801 - Train Accuracy: 72.40% - Test Accuracy: 73.99%\n",
      "[Epoch 42] LR: 0.1000 - Train Loss: 0.003900 - Test Loss: 0.003731 - Train Accuracy: 72.82% - Test Accuracy: 74.69%\n",
      "[Epoch 43] LR: 0.1000 - Train Loss: 0.003829 - Test Loss: 0.003517 - Train Accuracy: 73.38% - Test Accuracy: 75.79%\n",
      "[Epoch 44] LR: 0.1000 - Train Loss: 0.003760 - Test Loss: 0.003884 - Train Accuracy: 73.70% - Test Accuracy: 73.23%\n",
      "[Epoch 45] LR: 0.1000 - Train Loss: 0.003780 - Test Loss: 0.003670 - Train Accuracy: 73.63% - Test Accuracy: 74.55%\n",
      "[Epoch 46] LR: 0.1000 - Train Loss: 0.003731 - Test Loss: 0.003586 - Train Accuracy: 73.81% - Test Accuracy: 75.34%\n",
      "[Epoch 47] LR: 0.1000 - Train Loss: 0.003729 - Test Loss: 0.003904 - Train Accuracy: 73.85% - Test Accuracy: 72.77%\n",
      "[Epoch 48] LR: 0.1000 - Train Loss: 0.003679 - Test Loss: 0.003489 - Train Accuracy: 74.30% - Test Accuracy: 76.04%\n",
      "[Epoch 49] LR: 0.1000 - Train Loss: 0.003616 - Test Loss: 0.003514 - Train Accuracy: 74.85% - Test Accuracy: 76.58%\n",
      "[Epoch 50] LR: 0.1000 - Train Loss: 0.003577 - Test Loss: 0.003639 - Train Accuracy: 74.93% - Test Accuracy: 75.10%\n",
      "[Epoch 51] LR: 0.1000 - Train Loss: 0.003580 - Test Loss: 0.003339 - Train Accuracy: 74.89% - Test Accuracy: 77.00%\n",
      "[Epoch 52] LR: 0.1000 - Train Loss: 0.003499 - Test Loss: 0.003432 - Train Accuracy: 75.43% - Test Accuracy: 76.86%\n",
      "[Epoch 53] LR: 0.1000 - Train Loss: 0.003508 - Test Loss: 0.003918 - Train Accuracy: 75.46% - Test Accuracy: 73.95%\n",
      "[Epoch 54] LR: 0.1000 - Train Loss: 0.003490 - Test Loss: 0.003107 - Train Accuracy: 75.58% - Test Accuracy: 78.51%\n",
      "[Epoch 55] LR: 0.1000 - Train Loss: 0.003438 - Test Loss: 0.003780 - Train Accuracy: 76.07% - Test Accuracy: 74.89%\n",
      "[Epoch 56] LR: 0.1000 - Train Loss: 0.003427 - Test Loss: 0.003477 - Train Accuracy: 76.15% - Test Accuracy: 76.03%\n",
      "[Epoch 57] LR: 0.1000 - Train Loss: 0.003363 - Test Loss: 0.003191 - Train Accuracy: 76.61% - Test Accuracy: 77.82%\n",
      "[Epoch 58] LR: 0.1000 - Train Loss: 0.003378 - Test Loss: 0.003219 - Train Accuracy: 76.45% - Test Accuracy: 77.92%\n",
      "[Epoch 59] LR: 0.1000 - Train Loss: 0.003324 - Test Loss: 0.003358 - Train Accuracy: 76.69% - Test Accuracy: 76.91%\n",
      "[Epoch 60] LR: 0.1000 - Train Loss: 0.003330 - Test Loss: 0.003223 - Train Accuracy: 76.88% - Test Accuracy: 77.74%\n",
      "[Epoch 61] LR: 0.0100 - Train Loss: 0.002744 - Test Loss: 0.002540 - Train Accuracy: 81.11% - Test Accuracy: 82.65%\n",
      "[Epoch 62] LR: 0.0100 - Train Loss: 0.002542 - Test Loss: 0.002461 - Train Accuracy: 82.38% - Test Accuracy: 83.09%\n",
      "[Epoch 63] LR: 0.0100 - Train Loss: 0.002499 - Test Loss: 0.002457 - Train Accuracy: 82.61% - Test Accuracy: 82.98%\n",
      "[Epoch 64] LR: 0.0100 - Train Loss: 0.002482 - Test Loss: 0.002425 - Train Accuracy: 82.59% - Test Accuracy: 83.13%\n",
      "[Epoch 65] LR: 0.0100 - Train Loss: 0.002417 - Test Loss: 0.002474 - Train Accuracy: 83.03% - Test Accuracy: 83.13%\n",
      "[Epoch 66] LR: 0.0100 - Train Loss: 0.002423 - Test Loss: 0.002424 - Train Accuracy: 83.29% - Test Accuracy: 83.49%\n",
      "[Epoch 67] LR: 0.0100 - Train Loss: 0.002375 - Test Loss: 0.002479 - Train Accuracy: 83.47% - Test Accuracy: 82.82%\n",
      "[Epoch 68] LR: 0.0100 - Train Loss: 0.002367 - Test Loss: 0.002397 - Train Accuracy: 83.54% - Test Accuracy: 83.56%\n",
      "[Epoch 69] LR: 0.0100 - Train Loss: 0.002356 - Test Loss: 0.002385 - Train Accuracy: 83.65% - Test Accuracy: 83.74%\n",
      "[Epoch 70] LR: 0.0100 - Train Loss: 0.002332 - Test Loss: 0.002466 - Train Accuracy: 83.69% - Test Accuracy: 83.43%\n",
      "[Epoch 71] LR: 0.0100 - Train Loss: 0.002307 - Test Loss: 0.002417 - Train Accuracy: 83.88% - Test Accuracy: 83.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72] LR: 0.0100 - Train Loss: 0.002321 - Test Loss: 0.002409 - Train Accuracy: 83.69% - Test Accuracy: 83.83%\n",
      "[Epoch 73] LR: 0.0100 - Train Loss: 0.002302 - Test Loss: 0.002357 - Train Accuracy: 83.74% - Test Accuracy: 83.97%\n",
      "[Epoch 74] LR: 0.0100 - Train Loss: 0.002273 - Test Loss: 0.002380 - Train Accuracy: 84.05% - Test Accuracy: 83.92%\n",
      "[Epoch 75] LR: 0.0100 - Train Loss: 0.002278 - Test Loss: 0.002356 - Train Accuracy: 84.24% - Test Accuracy: 84.14%\n",
      "[Epoch 76] LR: 0.0100 - Train Loss: 0.002257 - Test Loss: 0.002391 - Train Accuracy: 84.20% - Test Accuracy: 83.65%\n",
      "[Epoch 77] LR: 0.0100 - Train Loss: 0.002243 - Test Loss: 0.002418 - Train Accuracy: 84.43% - Test Accuracy: 83.73%\n",
      "[Epoch 78] LR: 0.0100 - Train Loss: 0.002232 - Test Loss: 0.002323 - Train Accuracy: 84.42% - Test Accuracy: 84.05%\n",
      "[Epoch 79] LR: 0.0100 - Train Loss: 0.002215 - Test Loss: 0.002303 - Train Accuracy: 84.50% - Test Accuracy: 84.39%\n",
      "[Epoch 80] LR: 0.0100 - Train Loss: 0.002243 - Test Loss: 0.002305 - Train Accuracy: 84.29% - Test Accuracy: 84.12%\n",
      "[Epoch 81] LR: 0.0100 - Train Loss: 0.002202 - Test Loss: 0.002292 - Train Accuracy: 84.63% - Test Accuracy: 84.38%\n",
      "[Epoch 82] LR: 0.0100 - Train Loss: 0.002201 - Test Loss: 0.002305 - Train Accuracy: 84.51% - Test Accuracy: 84.42%\n",
      "[Epoch 83] LR: 0.0100 - Train Loss: 0.002202 - Test Loss: 0.002328 - Train Accuracy: 84.59% - Test Accuracy: 84.31%\n",
      "[Epoch 84] LR: 0.0100 - Train Loss: 0.002165 - Test Loss: 0.002332 - Train Accuracy: 84.64% - Test Accuracy: 84.41%\n",
      "[Epoch 85] LR: 0.0100 - Train Loss: 0.002162 - Test Loss: 0.002284 - Train Accuracy: 85.03% - Test Accuracy: 84.58%\n",
      "[Epoch 86] LR: 0.0100 - Train Loss: 0.002159 - Test Loss: 0.002281 - Train Accuracy: 84.89% - Test Accuracy: 84.59%\n",
      "[Epoch 87] LR: 0.0100 - Train Loss: 0.002139 - Test Loss: 0.002313 - Train Accuracy: 85.02% - Test Accuracy: 84.55%\n",
      "[Epoch 88] LR: 0.0100 - Train Loss: 0.002146 - Test Loss: 0.002288 - Train Accuracy: 84.97% - Test Accuracy: 84.54%\n",
      "[Epoch 89] LR: 0.0100 - Train Loss: 0.002137 - Test Loss: 0.002258 - Train Accuracy: 85.05% - Test Accuracy: 84.89%\n",
      "[Epoch 90] LR: 0.0100 - Train Loss: 0.002131 - Test Loss: 0.002316 - Train Accuracy: 84.96% - Test Accuracy: 84.46%\n",
      "[Epoch 91] LR: 0.0100 - Train Loss: 0.002110 - Test Loss: 0.002229 - Train Accuracy: 85.36% - Test Accuracy: 84.53%\n",
      "[Epoch 92] LR: 0.0100 - Train Loss: 0.002109 - Test Loss: 0.002278 - Train Accuracy: 85.16% - Test Accuracy: 84.62%\n",
      "[Epoch 93] LR: 0.0100 - Train Loss: 0.002074 - Test Loss: 0.002249 - Train Accuracy: 85.37% - Test Accuracy: 84.96%\n",
      "[Epoch 94] LR: 0.0100 - Train Loss: 0.002116 - Test Loss: 0.002270 - Train Accuracy: 85.20% - Test Accuracy: 84.48%\n",
      "[Epoch 95] LR: 0.0100 - Train Loss: 0.002086 - Test Loss: 0.002207 - Train Accuracy: 85.36% - Test Accuracy: 85.08%\n",
      "[Epoch 96] LR: 0.0100 - Train Loss: 0.002078 - Test Loss: 0.002294 - Train Accuracy: 85.43% - Test Accuracy: 84.74%\n",
      "[Epoch 97] LR: 0.0100 - Train Loss: 0.002052 - Test Loss: 0.002219 - Train Accuracy: 85.69% - Test Accuracy: 85.19%\n",
      "[Epoch 98] LR: 0.0100 - Train Loss: 0.002071 - Test Loss: 0.002281 - Train Accuracy: 85.42% - Test Accuracy: 84.43%\n",
      "[Epoch 99] LR: 0.0100 - Train Loss: 0.002028 - Test Loss: 0.002285 - Train Accuracy: 85.75% - Test Accuracy: 84.61%\n",
      "[Epoch 100] LR: 0.0100 - Train Loss: 0.002013 - Test Loss: 0.002239 - Train Accuracy: 86.01% - Test Accuracy: 85.10%\n",
      "[Epoch 101] LR: 0.0100 - Train Loss: 0.002020 - Test Loss: 0.002202 - Train Accuracy: 85.96% - Test Accuracy: 85.39%\n",
      "[Epoch 102] LR: 0.0100 - Train Loss: 0.002016 - Test Loss: 0.002187 - Train Accuracy: 85.81% - Test Accuracy: 85.30%\n",
      "[Epoch 103] LR: 0.0100 - Train Loss: 0.002025 - Test Loss: 0.002252 - Train Accuracy: 85.93% - Test Accuracy: 84.80%\n",
      "[Epoch 104] LR: 0.0100 - Train Loss: 0.002015 - Test Loss: 0.002214 - Train Accuracy: 86.06% - Test Accuracy: 85.28%\n",
      "[Epoch 105] LR: 0.0100 - Train Loss: 0.002001 - Test Loss: 0.002222 - Train Accuracy: 85.91% - Test Accuracy: 85.37%\n",
      "[Epoch 106] LR: 0.0100 - Train Loss: 0.002000 - Test Loss: 0.002200 - Train Accuracy: 85.99% - Test Accuracy: 84.97%\n",
      "[Epoch 107] LR: 0.0100 - Train Loss: 0.001998 - Test Loss: 0.002174 - Train Accuracy: 86.01% - Test Accuracy: 85.37%\n",
      "[Epoch 108] LR: 0.0100 - Train Loss: 0.001985 - Test Loss: 0.002238 - Train Accuracy: 85.98% - Test Accuracy: 84.89%\n",
      "[Epoch 109] LR: 0.0100 - Train Loss: 0.001982 - Test Loss: 0.002161 - Train Accuracy: 86.04% - Test Accuracy: 85.46%\n",
      "[Epoch 110] LR: 0.0100 - Train Loss: 0.001975 - Test Loss: 0.002176 - Train Accuracy: 86.12% - Test Accuracy: 85.35%\n",
      "[Epoch 111] LR: 0.0100 - Train Loss: 0.001980 - Test Loss: 0.002200 - Train Accuracy: 86.19% - Test Accuracy: 85.44%\n",
      "[Epoch 112] LR: 0.0100 - Train Loss: 0.001954 - Test Loss: 0.002238 - Train Accuracy: 86.37% - Test Accuracy: 85.12%\n",
      "[Epoch 113] LR: 0.0100 - Train Loss: 0.001937 - Test Loss: 0.002232 - Train Accuracy: 86.44% - Test Accuracy: 85.28%\n",
      "[Epoch 114] LR: 0.0100 - Train Loss: 0.001958 - Test Loss: 0.002197 - Train Accuracy: 86.24% - Test Accuracy: 85.24%\n",
      "[Epoch 115] LR: 0.0100 - Train Loss: 0.001934 - Test Loss: 0.002221 - Train Accuracy: 86.31% - Test Accuracy: 85.27%\n",
      "[Epoch 116] LR: 0.0010 - Train Loss: 0.001809 - Test Loss: 0.002103 - Train Accuracy: 87.32% - Test Accuracy: 85.97%\n",
      "[Epoch 117] LR: 0.0010 - Train Loss: 0.001745 - Test Loss: 0.002082 - Train Accuracy: 87.58% - Test Accuracy: 86.03%\n",
      "[Epoch 118] LR: 0.0010 - Train Loss: 0.001719 - Test Loss: 0.002066 - Train Accuracy: 87.96% - Test Accuracy: 86.31%\n",
      "[Epoch 119] LR: 0.0010 - Train Loss: 0.001722 - Test Loss: 0.002071 - Train Accuracy: 87.95% - Test Accuracy: 86.18%\n",
      "[Epoch 120] LR: 0.0010 - Train Loss: 0.001718 - Test Loss: 0.002070 - Train Accuracy: 87.94% - Test Accuracy: 86.34%\n",
      "[Epoch 121] LR: 0.0010 - Train Loss: 0.001695 - Test Loss: 0.002047 - Train Accuracy: 88.14% - Test Accuracy: 86.31%\n",
      "[Epoch 122] LR: 0.0010 - Train Loss: 0.001707 - Test Loss: 0.002066 - Train Accuracy: 87.92% - Test Accuracy: 86.19%\n",
      "[Epoch 123] LR: 0.0010 - Train Loss: 0.001708 - Test Loss: 0.002075 - Train Accuracy: 87.95% - Test Accuracy: 86.20%\n",
      "[Epoch 124] LR: 0.0010 - Train Loss: 0.001691 - Test Loss: 0.002070 - Train Accuracy: 88.12% - Test Accuracy: 86.35%\n",
      "[Epoch 125] LR: 0.0010 - Train Loss: 0.001674 - Test Loss: 0.002071 - Train Accuracy: 88.12% - Test Accuracy: 86.37%\n",
      "[Epoch 126] LR: 0.0010 - Train Loss: 0.001684 - Test Loss: 0.002062 - Train Accuracy: 88.00% - Test Accuracy: 86.39%\n",
      "[Epoch 127] LR: 0.0010 - Train Loss: 0.001709 - Test Loss: 0.002046 - Train Accuracy: 88.13% - Test Accuracy: 86.50%\n",
      "[Epoch 128] LR: 0.0010 - Train Loss: 0.001678 - Test Loss: 0.002052 - Train Accuracy: 88.12% - Test Accuracy: 86.46%\n",
      "[Epoch 129] LR: 0.0010 - Train Loss: 0.001675 - Test Loss: 0.002064 - Train Accuracy: 88.26% - Test Accuracy: 86.46%\n",
      "[Epoch 130] LR: 0.0010 - Train Loss: 0.001672 - Test Loss: 0.002076 - Train Accuracy: 88.19% - Test Accuracy: 86.25%\n",
      "[Epoch 131] LR: 0.0010 - Train Loss: 0.001684 - Test Loss: 0.002061 - Train Accuracy: 88.08% - Test Accuracy: 86.63%\n",
      "[Epoch 132] LR: 0.0010 - Train Loss: 0.001665 - Test Loss: 0.002045 - Train Accuracy: 88.25% - Test Accuracy: 86.53%\n",
      "[Epoch 133] LR: 0.0010 - Train Loss: 0.001652 - Test Loss: 0.002070 - Train Accuracy: 88.41% - Test Accuracy: 86.28%\n",
      "[Epoch 134] LR: 0.0010 - Train Loss: 0.001660 - Test Loss: 0.002053 - Train Accuracy: 88.30% - Test Accuracy: 86.49%\n",
      "[Epoch 135] LR: 0.0010 - Train Loss: 0.001658 - Test Loss: 0.002038 - Train Accuracy: 88.34% - Test Accuracy: 86.60%\n",
      "[Epoch 136] LR: 0.0010 - Train Loss: 0.001651 - Test Loss: 0.002051 - Train Accuracy: 88.42% - Test Accuracy: 86.77%\n",
      "[Epoch 137] LR: 0.0010 - Train Loss: 0.001651 - Test Loss: 0.002056 - Train Accuracy: 88.43% - Test Accuracy: 86.52%\n",
      "[Epoch 138] LR: 0.0010 - Train Loss: 0.001649 - Test Loss: 0.002045 - Train Accuracy: 88.34% - Test Accuracy: 86.81%\n",
      "[Epoch 139] LR: 0.0010 - Train Loss: 0.001658 - Test Loss: 0.002045 - Train Accuracy: 88.27% - Test Accuracy: 86.77%\n",
      "[Epoch 140] LR: 0.0010 - Train Loss: 0.001647 - Test Loss: 0.002043 - Train Accuracy: 88.27% - Test Accuracy: 86.57%\n",
      "[Epoch 141] LR: 0.0010 - Train Loss: 0.001658 - Test Loss: 0.002066 - Train Accuracy: 88.30% - Test Accuracy: 86.57%\n",
      "[Epoch 142] LR: 0.0001 - Train Loss: 0.001613 - Test Loss: 0.002055 - Train Accuracy: 88.70% - Test Accuracy: 86.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 143] LR: 0.0001 - Train Loss: 0.001626 - Test Loss: 0.002042 - Train Accuracy: 88.71% - Test Accuracy: 86.74%\n",
      "[Epoch 144] LR: 0.0001 - Train Loss: 0.001625 - Test Loss: 0.002048 - Train Accuracy: 88.66% - Test Accuracy: 86.70%\n",
      "[Epoch 145] LR: 0.0001 - Train Loss: 0.001628 - Test Loss: 0.002047 - Train Accuracy: 88.63% - Test Accuracy: 86.79%\n",
      "[Epoch 146] LR: 0.0001 - Train Loss: 0.001620 - Test Loss: 0.002047 - Train Accuracy: 88.61% - Test Accuracy: 86.63%\n",
      "[Epoch 147] LR: 0.0001 - Train Loss: 0.001611 - Test Loss: 0.002047 - Train Accuracy: 88.67% - Test Accuracy: 86.70%\n",
      "[Epoch 148] LR: 0.0000 - Train Loss: 0.001612 - Test Loss: 0.002047 - Train Accuracy: 88.63% - Test Accuracy: 86.81%\n",
      "[Epoch 149] LR: 0.0000 - Train Loss: 0.001628 - Test Loss: 0.002039 - Train Accuracy: 88.67% - Test Accuracy: 86.79%\n",
      "[Epoch 150] LR: 0.0000 - Train Loss: 0.001625 - Test Loss: 0.002058 - Train Accuracy: 88.53% - Test Accuracy: 86.68%\n",
      "[Epoch 151] LR: 0.0000 - Train Loss: 0.001639 - Test Loss: 0.002027 - Train Accuracy: 88.50% - Test Accuracy: 86.78%\n",
      "[Epoch 152] LR: 0.0000 - Train Loss: 0.001619 - Test Loss: 0.002031 - Train Accuracy: 88.69% - Test Accuracy: 86.82%\n",
      "[Epoch 153] LR: 0.0000 - Train Loss: 0.001632 - Test Loss: 0.002047 - Train Accuracy: 88.56% - Test Accuracy: 86.78%\n",
      "[Epoch 154] LR: 0.0000 - Train Loss: 0.001621 - Test Loss: 0.002044 - Train Accuracy: 88.59% - Test Accuracy: 86.77%\n",
      "[Epoch 155] LR: 0.0000 - Train Loss: 0.001627 - Test Loss: 0.002047 - Train Accuracy: 88.52% - Test Accuracy: 86.71%\n",
      "[Epoch 156] LR: 0.0000 - Train Loss: 0.001629 - Test Loss: 0.002060 - Train Accuracy: 88.58% - Test Accuracy: 86.69%\n",
      "[Epoch 157] LR: 0.0000 - Train Loss: 0.001613 - Test Loss: 0.002045 - Train Accuracy: 88.69% - Test Accuracy: 86.80%\n",
      "[Epoch 158] LR: 0.0000 - Train Loss: 0.001630 - Test Loss: 0.002044 - Train Accuracy: 88.42% - Test Accuracy: 86.71%\n",
      "[Epoch 159] LR: 0.0000 - Train Loss: 0.001605 - Test Loss: 0.002055 - Train Accuracy: 88.78% - Test Accuracy: 86.63%\n",
      "[Epoch 160] LR: 0.0000 - Train Loss: 0.001621 - Test Loss: 0.002039 - Train Accuracy: 88.58% - Test Accuracy: 86.76%\n",
      "[Epoch 161] LR: 0.0000 - Train Loss: 0.001626 - Test Loss: 0.002041 - Train Accuracy: 88.55% - Test Accuracy: 86.70%\n",
      "[Epoch 162] LR: 0.0000 - Train Loss: 0.001622 - Test Loss: 0.002040 - Train Accuracy: 88.61% - Test Accuracy: 86.64%\n",
      "[Epoch 163] LR: 0.0000 - Train Loss: 0.001616 - Test Loss: 0.002053 - Train Accuracy: 88.58% - Test Accuracy: 86.76%\n",
      "[Epoch 164] LR: 0.0000 - Train Loss: 0.001613 - Test Loss: 0.002046 - Train Accuracy: 88.72% - Test Accuracy: 86.69%\n",
      "[Epoch 165] LR: 0.0000 - Train Loss: 0.001619 - Test Loss: 0.002053 - Train Accuracy: 88.70% - Test Accuracy: 86.67%\n",
      "[Epoch 166] LR: 0.0000 - Train Loss: 0.001633 - Test Loss: 0.002036 - Train Accuracy: 88.57% - Test Accuracy: 86.75%\n",
      "[Epoch 167] LR: 0.0000 - Train Loss: 0.001624 - Test Loss: 0.002038 - Train Accuracy: 88.61% - Test Accuracy: 86.74%\n",
      "[Epoch 168] LR: 0.0000 - Train Loss: 0.001629 - Test Loss: 0.002024 - Train Accuracy: 88.40% - Test Accuracy: 86.84%\n",
      "[Epoch 169] LR: 0.0000 - Train Loss: 0.001623 - Test Loss: 0.002048 - Train Accuracy: 88.55% - Test Accuracy: 86.56%\n",
      "[Epoch 170] LR: 0.0000 - Train Loss: 0.001609 - Test Loss: 0.002066 - Train Accuracy: 88.68% - Test Accuracy: 86.69%\n",
      "[Epoch 171] LR: 0.0000 - Train Loss: 0.001619 - Test Loss: 0.002039 - Train Accuracy: 88.56% - Test Accuracy: 86.81%\n",
      "[Epoch 172] LR: 0.0000 - Train Loss: 0.001609 - Test Loss: 0.002054 - Train Accuracy: 88.80% - Test Accuracy: 86.62%\n",
      "[Epoch 173] LR: 0.0000 - Train Loss: 0.001629 - Test Loss: 0.002057 - Train Accuracy: 88.53% - Test Accuracy: 86.64%\n",
      "[Epoch 174] LR: 0.0000 - Train Loss: 0.001611 - Test Loss: 0.002043 - Train Accuracy: 88.70% - Test Accuracy: 86.58%\n",
      "[Epoch 175] LR: 0.0000 - Train Loss: 0.001608 - Test Loss: 0.002044 - Train Accuracy: 88.63% - Test Accuracy: 86.66%\n",
      "[Epoch 176] LR: 0.0000 - Train Loss: 0.001616 - Test Loss: 0.002048 - Train Accuracy: 88.68% - Test Accuracy: 86.67%\n",
      "[Epoch 177] LR: 0.0000 - Train Loss: 0.001628 - Test Loss: 0.002031 - Train Accuracy: 88.51% - Test Accuracy: 86.79%\n",
      "[Epoch 178] LR: 0.0000 - Train Loss: 0.001632 - Test Loss: 0.002039 - Train Accuracy: 88.46% - Test Accuracy: 86.71%\n",
      "[Epoch 179] LR: 0.0000 - Train Loss: 0.001648 - Test Loss: 0.002051 - Train Accuracy: 88.41% - Test Accuracy: 86.60%\n",
      "[Epoch 180] LR: 0.0000 - Train Loss: 0.001630 - Test Loss: 0.002039 - Train Accuracy: 88.64% - Test Accuracy: 86.68%\n",
      "[Epoch 181] LR: 0.0000 - Train Loss: 0.001620 - Test Loss: 0.002038 - Train Accuracy: 88.58% - Test Accuracy: 86.65%\n",
      "[Epoch 182] LR: 0.0000 - Train Loss: 0.001610 - Test Loss: 0.002041 - Train Accuracy: 88.53% - Test Accuracy: 86.68%\n",
      "[Epoch 183] LR: 0.0000 - Train Loss: 0.001620 - Test Loss: 0.002035 - Train Accuracy: 88.55% - Test Accuracy: 86.67%\n",
      "[Epoch 184] LR: 0.0000 - Train Loss: 0.001618 - Test Loss: 0.002050 - Train Accuracy: 88.80% - Test Accuracy: 86.68%\n",
      "[Epoch 185] LR: 0.0000 - Train Loss: 0.001622 - Test Loss: 0.002049 - Train Accuracy: 88.58% - Test Accuracy: 86.58%\n",
      "[Epoch 186] LR: 0.0000 - Train Loss: 0.001620 - Test Loss: 0.002049 - Train Accuracy: 88.45% - Test Accuracy: 86.65%\n",
      "[Epoch 187] LR: 0.0000 - Train Loss: 0.001615 - Test Loss: 0.002053 - Train Accuracy: 88.64% - Test Accuracy: 86.64%\n",
      "[Epoch 188] LR: 0.0000 - Train Loss: 0.001617 - Test Loss: 0.002050 - Train Accuracy: 88.65% - Test Accuracy: 86.66%\n",
      "[Epoch 189] LR: 0.0000 - Train Loss: 0.001628 - Test Loss: 0.002052 - Train Accuracy: 88.48% - Test Accuracy: 86.66%\n",
      "[Epoch 190] LR: 0.0000 - Train Loss: 0.001593 - Test Loss: 0.002044 - Train Accuracy: 88.72% - Test Accuracy: 86.59%\n",
      "[Epoch 191] LR: 0.0000 - Train Loss: 0.001614 - Test Loss: 0.002047 - Train Accuracy: 88.53% - Test Accuracy: 86.75%\n",
      "[Epoch 192] LR: 0.0000 - Train Loss: 0.001620 - Test Loss: 0.002034 - Train Accuracy: 88.47% - Test Accuracy: 86.83%\n",
      "[Epoch 193] LR: 0.0000 - Train Loss: 0.001606 - Test Loss: 0.002031 - Train Accuracy: 88.67% - Test Accuracy: 86.81%\n",
      "[Epoch 194] LR: 0.0000 - Train Loss: 0.001627 - Test Loss: 0.002060 - Train Accuracy: 88.53% - Test Accuracy: 86.62%\n",
      "[Epoch 195] LR: 0.0000 - Train Loss: 0.001605 - Test Loss: 0.002036 - Train Accuracy: 88.73% - Test Accuracy: 86.72%\n",
      "[Epoch 196] LR: 0.0000 - Train Loss: 0.001610 - Test Loss: 0.002057 - Train Accuracy: 88.64% - Test Accuracy: 86.61%\n",
      "[Epoch 197] LR: 0.0000 - Train Loss: 0.001617 - Test Loss: 0.002047 - Train Accuracy: 88.65% - Test Accuracy: 86.67%\n",
      "[Epoch 198] LR: 0.0000 - Train Loss: 0.001609 - Test Loss: 0.002060 - Train Accuracy: 88.65% - Test Accuracy: 86.75%\n",
      "[Epoch 199] LR: 0.0000 - Train Loss: 0.001618 - Test Loss: 0.002039 - Train Accuracy: 88.60% - Test Accuracy: 86.67%\n",
      "[Epoch 200] LR: 0.0000 - Train Loss: 0.001640 - Test Loss: 0.002054 - Train Accuracy: 88.40% - Test Accuracy: 86.66%\n",
      "Finished Training\n",
      "Best Test accuracy: 86.84%\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"\\n---- Start Training ----\")\n",
    "best_accuracy = -1\n",
    "for i in range(epochs):\n",
    "\n",
    "    # TRAIN THE NETWORK\n",
    "    train_loss, train_correct = 0, 0\n",
    "    net.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "        train_correct += pred.eq(targets).sum().item()\n",
    "\n",
    "        # print statistics\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # TEST NETWORK\n",
    "    net.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            test_loss += criterion(outputs, targets)\n",
    "            _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    # Get current learning rate via the optimizer\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "    \n",
    "    print(\"[Epoch {}] LR: {:.4f} - Train Loss: {:.6f} - Test Loss: {:.6f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(\n",
    "            epoch + 1, current_lr, train_loss, test_loss, 100. * train_correct / len(train_loader.dataset), test_accuracy\n",
    "        ))\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        \n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    epoch += 1\n",
    "\n",
    "print(\"Finished Training\")\n",
    "print(\"Best Test accuracy: {:.2f}%\".format(best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./models/cifar_conv_param_state.pt\")\n",
    "torch.save(optimizer.state_dict(), \"./models/cifar_conv_optim_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
